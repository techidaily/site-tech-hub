---
title: "Unveiling the Latest Upgrade: Google Imagen 2 Video Generation Capabilities"
date: 2024-08-28 20:14:39
updated: 2024-08-29 12:12:21
tags:
  - cutting-edge
categories:
  - tech
thumbnail: https://thmb.techidaily.com/92b52bcf62734b2a9c93d0aaee5e581aafbb53c0651a85c9e09e34c344274922.jpg
---

## Unveiling the Latest Upgrade: Google Imagen 2 Video Generation Capabilities

It hasn't really been too long since OpenAI showed off Sora, which impressed and frightened many people with its ability to make (somewhat) realistic video clips out of text prompts. AI image generation has been polished a lot over the past months, so as you might expect, the next natural step is video. Google is also coming out with its own video generation methods, with new AI models under the umbrella of Imagen 2 promising big things as well.

 Google introduced Imagen 2, a family of models within its Vertex AI platform. Google came under fire for its [image generation model within Gemini](https://some-knowledge.techidaily.com/updated-from-novice-to-expert-your-path-in-google-photos/) being a bit of a dumpster fire. It was removed, and while Gemini isn't including Imagen 2 (at least not straight away), it does come with a series of improvements that make it all-in-all better for generating images or even video.

 Enhancements to Imagen 2 include inpainting and outpainting features, allowing for image manipulation such as removal of unwanted elements or addition of new components. The most significant update, however, is the introduction of "text-to-live images," enabling the creation of short videos from text inputs.

 However, you should keep in mind that this is not [Sora](https://some-guidance.techidaily.com/unveiling-the-art-of-cinematography-basic-shots-explained-for-2024/). Compared to existing video generation tools, Imagen 2's capabilities might fall short in terms of resolution and customization options. We'll have to see how well it does in real-life usage. It's also a bit of a technicality, but this generates "live images," which are short, 4-second clips. It's still a start, however, and this could serve as a foundation for an actual text-to-video model within the next months or years.

 To address concerns regarding deepfakes, Google incorporates SynthID technology to apply cryptographic watermarks to live images, aiming for authenticity and safety. Despite Google's emphasis on safety measures, questions remain about the effectiveness of its approach and transparency regarding training data sources. The absence, for one, of an opt-out mechanism for creators whose work may be included in the training data might raise eyebrows for some. Additionally, Google's generative AI indemnification policy does not cover text-to-live images, leaving customers vulnerable to potential copyright claims.

 We'll have to wait and see whether Google makes this publicly accessible in any way. We might hear more once Google I/O rolls around.

 Source: [TechCrunch](https://techcrunch.com/2024/04/09/google-releases-imagen-2-a-video-clip-generator/?guccounter=1&guce%5Freferrer=aHR0cHM6Ly9hcHAuYXNhbmEuY29tLw&guce%5Freferrer%5Fsig=AQAAANi06qDCBED6GNbmhC6JtZakGqXm5kVyKOjH3W8IOAOmZFminQJ7YHs5bQx7E%5Fi8-TStui78S8rruAwrWMg18nAwb1WOaSil-7yNTMIng-UVvkPd-fK2C8vV511YmfnJiT-GZgyAO1AUzJnlKuWT5chS1QBP6E8oVhNMO6VTiNfN)

<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="1223367746"></ins>



<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="8358498916"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

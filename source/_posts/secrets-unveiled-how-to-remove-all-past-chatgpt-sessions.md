---
title: "Secrets Unveiled: How to Remove All Past ChatGPT Sessions"
date: 2024-08-15T21:53:07.194Z
updated: 2024-08-16T21:53:07.194Z
tags:
  - chatgpt
  - open-ai
categories:
  - openAI
  - chatgpt
description: "This Article Describes Secrets Unveiled: How to Remove All Past ChatGPT Sessions"
excerpt: "This Article Describes Secrets Unveiled: How to Remove All Past ChatGPT Sessions"
thumbnail: https://thmb.techidaily.com/39537ef670f74abdd3937163bf686c62a000d8146ce98f4b0e1e21a62378c3d8.jpg
---

## Llama ˈLocal-Ization' Guide: How to Install and Use It Yourself

 Meta released Llama 2 in the summer of 2023\. The new version of Llama is fine-tuned with 40% more tokens than the original Llama model, doubling its context length and significantly outperforming other open-sourced models available. The fastest and easiest way to access Llama 2 is via an API through an online platform. However, if you want the best experience, installing and loading Llama 2 directly on your computer is best.

 With that in mind, we've created a step-by-step guide on how to use Text-Generation-WebUI to load a quantized Llama 2 LLM locally on your computer.

<!-- affiliate ads begin -->
<a href="https://arkmc.pxf.io/c/5597632/427477/5172" target="_top" id="427477"><img src="//a.impactradius-go.com/display-ad/5172-427477" border="0" alt="" width="728" height="90"/></a><img height="0" width="0" src="https://arkmc.pxf.io/i/5597632/427477/5172" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## Why Install Llama 2 Locally

 There are many reasons why people choose to run Llama 2 directly. Some do it for privacy concerns, some for customization, and others for offline capabilities. If you're researching, fine-tuning, or integrating Llama 2 for your projects, then accessing Llama 2 via API might not be for you. The point of running an LLM locally on your PC is to reduce reliance on[third-party AI tools](https://www.makeuseof.com/best-ai-web-apps/) and use AI anytime, anywhere, without worrying about leaking potentially sensitive data to companies and other organizations.

 With that said, let's begin with the step-by-step guide to installing Llama 2 locally.

## Step 1: Install Visual Studio 2019 Build Tool

 To simplify things, we will use a one-click installer for Text-Generation-WebUI (the program used to load Llama 2 with GUI). However, for this installer to work, you need to download the Visual Studio 2019 Build Tool and install the necessary resources.

**Download:** [Visual Studio 2019](https://learn.microsoft.com/en-us/visualstudio/releases/2019/release-notes) (Free)

1. Go ahead and download the community edition of the software.
2. Now install Visual Studio 2019, then open the software. Once opened, tick the box on**Desktop development with C++** and hit install.  
![Install-Desktop-Development-With-C++](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/2-install-desktop-development-with-c.jpg)

 Now that you have Desktop development with C++ installed, it's time to download the Text-Generation-WebUI one-click installer.

## Step 2: Install Text-Generation-WebUI

 The Text-Generation-WebUI one-click installer is a script that automatically creates the required folders and sets up the Conda environment and all necessary requirements to run an AI model.

 To install the script, download the one-click installer by clicking on**Code** \>**Download ZIP.**

**Download:** [Text-Generation-WebUI Installer](https://github.com/oobabooga/text-generation-webui/tree/main) (Free)

1. Once downloaded, extract the ZIP file to your preferred location, then open the extracted folder.
2. Within the folder, scroll down and look for the appropriate start program for your operating system. Run the programs by double-clicking the appropriate script.  
   * If you are on Windows, select**start\_windows** batch file  
   * for MacOS, select**start\_macos** shell scrip  
   * for Linux,**start\_linux** shell script.  
<!-- affiliate ads begin -->
<a href="https://checkout.mirillis.com/order/checkout.php?PRODS=4704640&QTY=1&AFFILIATE=108875&CART=1"> <img src="https://secure.avangate.com/images/merchant/547a5a56d43f6d40f9a6a2f76501d013/products/1_mirillis_action_boxshot_store_1x.jpg" border="0">
	Home Use license is dedicated for personal, non-commercial use only. 
	If Action! is used for commercial gain or to further any commercial purpose, 
	a Commercial Use license is required. Multi-license (volume discount) is intended for single 
 
	company, user or members of the same household. Action! - screen and game recorder</a>
<!-- affiliate ads end -->
   ![Select operating system](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/4-select-operating-system.jpg)
3. Your anti-virus might create an alert; this is fine. The prompt is just an[antivirus false positive](https://www.makeuseof.com/what-is-antivirus-false-result/) for running a batch file or script. Click on**Run anyway** .
4. A terminal will open and start the setup. Early on, the setup will pause and ask you what GPU you are using. Select the appropriate type of GPU installed on your computer and hit enter. For those without a dedicated graphics card, select**None (I want to run models in CPU mode)** . Keep in mind that running on CPU mode is much slower when compared to running the model with a dedicated GPU.  
<!-- affiliate ads begin -->
<a href="https://aligracehair.sjv.io/c/5597632/2087264/19272" target="_top" id="2087264"><img src="//a.impactradius-go.com/display-ad/19272-2087264" border="0" alt="" width="336" height="280"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/2087264/19272" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
![Selecting GPU hardware installed](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/5-select-gpu-settings.jpg)
5. Once the setup is complete, you can now launch Text-Generation-WebUI locally. You can do so by opening your preferred web browser and entering the provided IP address on the URL.  
<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4620778&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/07dd4d5a72f5740ef0f035f201951476/728__90banner.jpg" border="0"></a>
<!-- affiliate ads end -->
![How to launch-Text-Generation-WebUI](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/6-launch-text-generation-webui.jpg)
6. The WebUI is now ready for use.  
<!-- affiliate ads begin -->
<a href="https://appsumo.8odi.net/c/5597632/2075475/7443" target="_top" id="2075475"><img src="//a.impactradius-go.com/display-ad/7443-2075475" border="0" alt="" width="1200" height="600"/></a><img height="0" width="0" src="https://appsumo.8odi.net/i/5597632/2075475/7443" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
![Text-Generation-WebUI ](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/7-text-generation-webui-view.jpg)

 However, the program is only a model loader. Let's download Llama 2 for the model loader to launch.

## Step 3: Download the Llama 2 Model

 There are quite a few things to consider when deciding which iteration of Llama 2 you need. These include parameters, quantization, hardware optimization, size, and usage. All of this information will be found denoted in the model's name.

* **Parameters:** The number of parameters used to train the model. Bigger parameters make more capable models but at the cost of performance.
* **Usage:** Can either be standard or chat. A chat model is optimized to be used as a chatbot like ChatGPT, while the standard is the default model.
* **Hardware Optimization:** Refers to what hardware best runs the model. GPTQ means the model is optimized to run on a dedicated GPU, while GGML is optimized to run on a CPU.
* **Quantization:** Denotes the precision of weights and activations in a model. For inferencing, a precision of q4 is optimal.
* **Size:** Refers to the size of the specific model.

 Note that some models may be arranged differently and may not even have the same types of information displayed. However, this type of naming convention is fairly common in the[HuggingFace](https://www.makeuseof.com/what-is-hugging-face-and-what-is-it-used-for/) Model library, so it's still worth understanding.

<!-- affiliate ads begin -->
<a href="https://united.elfm.net/c/5597632/517826/4704" target="_top" id="517826"><img src="//a.impactradius-go.com/display-ad/4704-517826" border="0" alt="" width="728" height="90"/></a><img height="0" width="0" src="https://united.elfm.net/i/5597632/517826/4704" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
![HuggingFace model naming convention](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/wm/2023/10/huggingface-model-naming-convention-1.jpg)

 In this example, the model can be identified as a medium-sized Llama 2 model trained on 13 billion parameters optimized for chat inferencing using a dedicated CPU.

 For those running on a dedicated GPU, choose a**GPTQ** model, while for those using a CPU, choose**GGML** . If you want to chat with the model like you would with ChatGPT, choose**chat** , but if you want to experiment with the model with its full capabilities, use the**standard** model. As for parameters, know that using bigger models will provide better results at the expense of performance. I would personally recommend you start with a 7B model. As for quantization, use q4, as it's only for inferencing.

**Download:** [GGML](https://huggingface.co/localmodels/Llama-2-7B-ggml/tree/main) (Free)

**Download:** [GPTQ](https://huggingface.co/localmodels/Llama-2-7B-Chat-GPTQ/tree/main) (Free)

 Now that you know what iteration of Llama 2 you need, go ahead and download the model you want.

 In my case, since I'm running this on an ultrabook, I'll be using a GGML model fine-tuned for chat,**llama-2-7b-chat-ggmlv3.q4\_K\_S.bin.**

![Downloading Llama 2 model of your preference](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/8-download-llama-2-model.jpg)

 After the download is finished, place the model in**text-generation-webui-main** \>**models** .

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=35038891&QTY=1&AFFILIATE=108875&CART=1"><img src="https://www.dupinout.com/wp-content/uploads/2021/12/DupInOut-New-Duplicate-Scan-Tab.png" border="0"></a>
<!-- affiliate ads end -->
![Placing Llama 2 model to model folder](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/9-place-model-to-model-folder.jpg)

 Now that you have your model downloaded and placed in the model folder, it's time to configure the model loader.

## Step 4: Configure Text-Generation-WebUI

Now, let's begin the configuration phase.

1. Once again, open Text-Generation-WebUI by running the**start\_(your OS)** file (see the previous steps above).
2. On the tabs located above the GUI, click**Model.** Click the refresh button at the model dropdown menu and select your model.
3. Now click on the dropdown menu of the**Model loader** and select**AutoGPTQ** for those using a GTPQ model and**ctransformers** for those using a GGML model. Finally, click on**Load** to load your model.  
![Setting model loader](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/10-select-model-loader.jpg)
4. To use the model, open the Chat tab and start testing the model.  
![Testing Llama 2 locally](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/12-testing-llama-2-locally.jpg)

 Congratulations, you've successfully loaded Llama2 on your local computer!

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4599952&QTY=1&AFFILIATE=108875&CART=1"><iframe width="864" height="500" src="https://www.youtube.com/embed/jVnfr5HudQw" title="The Latest and Easiest Solution to Remove Kindle DRM on Windows (without Degrading)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>Epubor Ultimate for Mac:Helps you read books anywhere, including the best eBook Converter + eBook DRM Removal functions.</a>
<!-- affiliate ads end -->
## Try Out Other LLMs

 Now that you know how to run Llama 2 directly on your computer using Text-Generation-WebUI, you should also be able to run other LLMs besides Llama. Just remember the naming conventions of models and that only quantized versions of models (usually q4 precision) can be loaded on regular PCs. Many quantized LLMs are available on HuggingFace. If you want to explore other models, search for TheBloke in HuggingFace's model library, and you should find many models available.


<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="1223367746"></ins>



<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="8358498916"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<span class="atpl-alsoreadstyle">Also read:</span>
<div><ul>
<li><a href="https://eaxpv-info.techidaily.com/new-fresh-footage-frequent-flows-dos-and-donts-for-streamlining-video-content-for-2024/"><u>[New] Fresh Footage, Frequent Flows  Do's & Don'ts for Streamlining Video Content for 2024</u></a></li>
<li><a href="https://snapchat-videos.techidaily.com/updated-decoding-advanced-techniques-for-flawless-snapchat-edits-for-2024/"><u>[Updated] Decoding Advanced Techniques for Flawless Snapchat Edits for 2024</u></a></li>
<li><a href="https://facebook-record-videos.techidaily.com/updated-in-2024-crafting-a-signature-look-starting-with-self-reflection/"><u>[Updated] In 2024, Crafting a Signature Look  Starting with Self-Reflection</u></a></li>
<li><a href="https://youtube-docs.techidaily.com/ed-zero-price-strategies-for-solo-frame-analysis-in-videos/"><u>[Updated] Zero-Price Strategies for Solo Frame Analysis in Videos</u></a></li>
<li><a href="https://extra-resources.techidaily.com/2024-approved-collaborative-filmmaking-teamwork-in-producing-instagram-content/"><u>2024 Approved  Collaborative Filmmaking  Teamwork in Producing Instagram Content</u></a></li>
<li><a href="https://tech-hub.techidaily.com/5-essential-ai-tools-every-entrepreneur-must-explore/"><u>5 Essential AI Tools Every Entrepreneur Must Explore</u></a></li>
<li><a href="https://tech-hub.techidaily.com/a-side-by-side-analysis-of-mistral-ait-le-chat-against-chatgpt/"><u>A Side by Side Analysis of Mistral AI't Le Chat Against ChatGPT</u></a></li>
<li><a href="https://fox-that.techidaily.com/1721467960927-airpods-connectivity-woes-discover-6-fixes-for-seamless-transition-between-all-apple-devices/"><u>AirPods Connectivity Woes? Discover 6 Fixes for Seamless Transition Between All Apple Devices</u></a></li>
<li><a href="https://tech-hub.techidaily.com/artificial-intelligence-misinterpretations-how-to-discern-and-manage-inaccurate-results/"><u>Artificial Intelligence Misinterpretations: How To Discern And Manage Inaccurate Results</u></a></li>
<li><a href="https://tech-hub.techidaily.com/authenticating-medical-data-trustworthy-practices-using-chatgpt-and-advanced-ai/"><u>Authenticating Medical Data: Trustworthy Practices Using ChatGPT & Advanced AI</u></a></li>
<li><a href="https://tech-hub.techidaily.com/battle-of-the-ai-giants-determining-the-best-large-language-model-llm-amongst-bard-chatgpt-and-offline-alpaca/"><u>Battle of the AI Giants: Determining the Best Large Language Model (LLM) Amongst Bard, ChatGPT, & Offline Alpaca</u></a></li>
<li><a href="https://youtube-webster.techidaily.com/-shots-for-youtube-filmmakers-for-2024/"><u>Clear Shots for YouTube Filmmakers for 2024</u></a></li>
<li><a href="https://data-safeguard.techidaily.com/consumer-centric-innovation-stellar-unveils-upgraded-data-recovery-software/"><u>Consumer-Centric Innovation: Stellar Unveils Upgraded Data Recovery Software</u></a></li>
<li><a href="https://tech-hub.techidaily.com/content-monitoring-woes-the-unseen-threat/"><u>Content Monitoring Woes: The Unseen Threat</u></a></li>
<li><a href="https://buynow-info.techidaily.com/discovering-the-gems-in-affordability-an-in-depth-look-at-beantechs-bitwatch-s1plus-wearable-tech/"><u>Discovering the Gems in Affordability - An In-Depth Look at Beantech's Bitwatch S1+ Wearable Tech</u></a></li>
<li><a href="https://tiktok-video-recordings.techidaily.com/finding-the-right-wordmark-for-your-personalized-tiktok-stream/"><u>Finding the Right Wordmark for Your Personalized TikTok Stream</u></a></li>
<li><a href="https://unlock-android.techidaily.com/forgot-pattern-lock-heres-how-you-can-unlock-itel-p40plus-pattern-lock-screen-by-drfone-android/"><u>Forgot Pattern Lock? Heres How You Can Unlock Itel P40+ Pattern Lock Screen</u></a></li>
<li><a href="https://android-unlock.techidaily.com/full-tutorial-to-bypass-your-vivo-y77t-face-lock-by-drfone-android/"><u>Full Tutorial to Bypass Your Vivo Y77t Face Lock?</u></a></li>
<li><a href="https://hardware-help.techidaily.com/how-to-obtain-the-newest-epson-l3150-driver-compatible-with-windows-1087-systems/"><u>How to Obtain the Newest Epson L3150 Driver: Compatible with Windows 10/8/7 Systems</u></a></li>
<li><a href="https://screen-recording.techidaily.com/in-2024-how-to-record-screen-with-panopto-screen-recorder/"><u>In 2024, How To Record Screen With Panopto Screen Recorder</u></a></li>
<li><a href="https://sim-unlock.techidaily.com/in-2024-the-6-best-sim-unlock-services-that-actually-work-on-your-meizu-device-by-drfone-android/"><u>In 2024, The 6 Best SIM Unlock Services That Actually Work On Your Meizu Device</u></a></li>
<li><a href="https://tech-hub.techidaily.com/quick-deployment-discover-these-8-easy-to-use-tailored-gpt-variants/"><u>Quick Deployment: Discover These 8 Easy-To-Use Tailored GPT Variants</u></a></li>
<li><a href="https://tech-hub.techidaily.com/reimagine-the-classroom-with-ai-educators-guide-to-understanding-its-potential-eight-essential-reasons-to-embrace-it-now/"><u>Reimagine the Classroom with AI: Educators' Guide to Understanding Its Potential – Eight Essential Reasons to Embrace It Now</u></a></li>
<li><a href="https://tech-hub.techidaily.com/revolutionize-hr-efficiency-5-effective-prompts-using-advanced-language-models/"><u>Revolutionize HR Efficiency: 5 Effective Prompts Using Advanced Language Models</u></a></li>
<li><a href="https://tech-hub.techidaily.com/revolutionize-your-business-with-these-8-key-uses-of-chatgpt/"><u>Revolutionize Your Business with These 8 Key Uses of ChatGPT</u></a></li>
<li><a href="https://tech-hub.techidaily.com/scripting-success-with-chatgpt-the-story-of-my-podcast-journey/"><u>Scripting Success with ChatGPT: The Story of My Podcast Journey</u></a></li>
<li><a href="https://tech-hub.techidaily.com/speak-up-5-techniques-to-command-chatgpt-through-voice-commands/"><u>Speak Up: 5 Techniques to Command ChatGPT Through Voice Commands</u></a></li>
<li><a href="https://tech-hub.techidaily.com/supercharge-your-experience-check-out-our-1-9-gpt-plugins/"><u>Supercharge Your Experience – Check Out Our #1-#9 GPT Plugins</u></a></li>
<li><a href="https://tech-hub.techidaily.com/the-art-of-crafting-engaging-stories-harnessing-the-power-of-chatgpt-for-storytellers/"><u>The Art of Crafting Engaging Stories: Harnessing the Power of ChatGPT for Storytellers</u></a></li>
<li><a href="https://tech-hub.techidaily.com/the-finest-ai-idea-exchanges-in-the-digital-realm/"><u>The Finest AI Idea Exchanges in the Digital Realm</u></a></li>
<li><a href="https://tech-hub.techidaily.com/the-future-is-now-how-generative-ai-like-chatgpt-could-revolutionize-job-roles/"><u>The Future Is Now: How Generative AI Like ChatGPT Could Revolutionize Job Roles</u></a></li>
<li><a href="https://tech-hub.techidaily.com/the-ultimate-guide-to-effective-chatbot-services-selection/"><u>The Ultimate Guide to Effective Chatbot Services Selection</u></a></li>
<li><a href="https://tech-hub.techidaily.com/the-ultimate-resource-for-writing-youtube-videos-with-chatgpt/"><u>The Ultimate Resource for Writing YouTube Videos with ChatGPT</u></a></li>
<li><a href="https://tech-hub.techidaily.com/transformative-technology-discover-6-new-avenues-with-chatgpts-code-conductor/"><u>Transformative Technology - Discover 6 New Avenues with ChatGPT's Code Conductor</u></a></li>
<li><a href="https://tech-hub.techidaily.com/understanding-the-hierarchy-unpacking-the-distinctions-between-gpt-4-versions/"><u>Understanding the Hierarchy: Unpacking the Distinctions Between GPT-4 Versions</u></a></li>
<li><a href="https://tech-hub.techidaily.com/unleashing-potential-build-a-one-of-a-kind-chatgpt/"><u>Unleashing Potential: Build a One-of-a-Kind ChatGPT</u></a></li>
<li><a href="https://tech-hub.techidaily.com/unlock-word-potential-with-ai-powered-automated-drafting/"><u>Unlock Word Potential with AI-Powered Automated Drafting</u></a></li>
<li><a href="https://tech-hub.techidaily.com/unveiling-5-premium-ai-prompt-inventors-that-work-seamlessly-across-diverse-artificial-intelligence-platforms/"><u>Unveiling 5 Premium AI Prompt Inventors That Work Seamlessly Across Diverse Artificial Intelligence Platforms</u></a></li>
<li><a href="https://tech-hub.techidaily.com/validating-wellness-information-in-the-age-of-ai-methods-to-assess-reliability-using-chatgpt/"><u>Validating Wellness Information in the Age of AI: Methods to Assess Reliability Using ChatGPT</u></a></li>
<li><a href="https://tech-hub.techidaily.com/what-lies-ahead-in-generative-ai-development-following-chatgpt-breakthroughs/"><u>What Lies Ahead in Generative AI Development Following ChatGPT Breakthroughs?</u></a></li>
<li><a href="https://tech-hub.techidaily.com/why-relying-on-zerogpt-or-similar-ai-detectors-may-be-risky-insightful-cases/"><u>Why Relying on ZeroGPT or Similar AI Detectors May Be Risky: Insightful Cases</u></a></li>
<li><a href="https://tech-hub.techidaily.com/your-guide-to-online-safety-tackling-the-surge-of-twitter-scams-celebrating-metas-official-verification-launch-and-exploring-chatgpt-4/"><u>Your Guide to Online Safety: Tackling the Surge of Twitter Scams, Celebrating Meta's Official Verification Launch & Exploring ChatGPT-4</u></a></li>
</ul></div>
